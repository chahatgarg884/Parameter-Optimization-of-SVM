{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPvavv7eBjbl3N3Uk4I0bJG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chahatgarg884/Parameter-Optimization-of-SVM/blob/main/Parameter_Optimization_of_SVM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "kcKvMMKE4Hn-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ebf0508-967e-4890-cc54-bdd70c59595b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Sample  Accuracy  Kernel     C  Epsilon\n",
            "0     S1      0.00  linear   1.0     0.50\n",
            "1     S2      0.00  linear   0.1     0.50\n",
            "2     S3     16.67     rbf  10.0     0.01\n",
            "3     S4      0.00     rbf  10.0     0.01\n",
            "4     S5      0.00     rbf  10.0     0.50\n",
            "5     S6      0.00     rbf  10.0     0.50\n",
            "6     S7     16.67     rbf  10.0     0.10\n",
            "7     S8      0.00     rbf  10.0     0.01\n",
            "8     S9      0.00     rbf  10.0     0.10\n",
            "9    S10     16.67     rbf  10.0     0.50\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Load Dataset\n",
        "column_names = ['letter', 'x-box', 'y-box', 'width', 'high', 'onpix', 'x-bar',\n",
        "                'y-bar', 'x2bar', 'y2bar', 'xybar', 'x2ybr', 'xy2br',\n",
        "                'x-ege', 'xegvy', 'y-ege', 'yegvx']\n",
        "\n",
        "data = pd.read_csv(\"/content/letter-recognition.csv\", names=column_names)\n",
        "\n",
        "# Encode labels\n",
        "X = data.drop('letter', axis=1)\n",
        "y = LabelEncoder().fit_transform(data['letter'])\n",
        "\n",
        "# Define parameter grid\n",
        "param_grid = {\n",
        "    'svr__kernel': ['linear', 'rbf', 'poly'],\n",
        "    'svr__C': [0.1, 1, 10],\n",
        "    'svr__epsilon': [0.01, 0.1, 0.5]\n",
        "}\n",
        "\n",
        "results = []\n",
        "all_convergences = []\n",
        "\n",
        "# Run optimization 10 times\n",
        "for i in range(10):\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.3, random_state=i)\n",
        "\n",
        "    pipeline = Pipeline([\n",
        "        ('scaler', StandardScaler()),\n",
        "        ('svr', SVR())\n",
        "    ])\n",
        "\n",
        "    grid = GridSearchCV(pipeline, param_grid, cv=3, verbose=0)\n",
        "    grid.fit(X_train, y_train)\n",
        "\n",
        "    y_pred = grid.predict(X_test)\n",
        "    y_pred_class = np.round(y_pred).astype(int)\n",
        "    y_pred_class = np.clip(y_pred_class, 0, len(np.unique(y))-1)\n",
        "    acc = accuracy_score(y_test, y_pred_class)\n",
        "\n",
        "    results.append({\n",
        "        'Sample': f\"S{i+1}\",\n",
        "        'Accuracy': round(acc*100, 2),\n",
        "        'Kernel': grid.best_params_['svr__kernel'],\n",
        "        'C': grid.best_params_['svr__C'],\n",
        "        'Epsilon': grid.best_params_['svr__epsilon'],\n",
        "        'Model': grid.best_estimator_\n",
        "    })\n",
        "\n",
        "    # Simulate convergence (not real optimization loss, just accuracy over time)\n",
        "    accs = []\n",
        "    for j in range(1, 101):\n",
        "        idx = max(1, int(len(X_train) * (j / 100)))  # âœ… Fix: Ensure at least 1 sample\n",
        "        model = grid.best_estimator_\n",
        "        model.fit(X_train[:idx], y_train[:idx])\n",
        "        y_p = model.predict(X_test)\n",
        "        y_p_c = np.round(y_p).astype(int)\n",
        "        y_p_c = np.clip(y_p_c, 0, len(np.unique(y))-1)\n",
        "        accs.append(accuracy_score(y_test, y_p_c) * 100)\n",
        "\n",
        "    all_convergences.append(accs)\n",
        "\n",
        "# Get best performing sample\n",
        "best_idx = np.argmax([r['Accuracy'] for r in results])\n",
        "best_convergence = all_convergences[best_idx]\n",
        "\n",
        "\n",
        "# Save table results\n",
        "df_results = pd.DataFrame(results)[['Sample', 'Accuracy', 'Kernel', 'C', 'Epsilon']]\n",
        "df_results.to_csv(\"svm_results.csv\", index=False)\n",
        "print(df_results)"
      ]
    }
  ]
}